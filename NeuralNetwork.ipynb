{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class Module:\n",
    "    def zero_grad(self):\n",
    "        for p in self.parameters():\n",
    "            p.grad = 0\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "class Neuron(Module):\n",
    "    def __init__(self,nin):\n",
    "        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n",
    "        self.b = Value(random.uniform(-1,1))\n",
    "    def __call__(self,nin):\n",
    "        act = sum(wi*xi for wi,xi in zip(self.w,nin) ) + self.b\n",
    "        out = act.tanh()\n",
    "        return out\n",
    "    def parameter(self):\n",
    "        return self.w + [self.b] \n",
    "class Layer(Module):\n",
    "    def __init__(self,nin,nout):\n",
    "         self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "    def __call__(self,nin):\n",
    "        outs = [n(nin) for n in self.neurons]\n",
    "        return outs[0] if len(outs)==1 else outs\n",
    "    def parameter(self):\n",
    "        params =[]\n",
    "        for neuron in self.neurons:\n",
    "            ps=neuron.parameter()\n",
    "            params.extend(ps) \n",
    "        return params\n",
    "class MLP(Module):\n",
    "    def __init__(self,nin,nouts):\n",
    "        size = [nin] + nouts\n",
    "        self.layer=[ Layer(size[i],size[i+1]) for i in range(len(nouts)) ]\n",
    "    def __call__(self,nouts):\n",
    "        for layer in self.layer:\n",
    "            nouts = layer(nouts)\n",
    "        return nouts \n",
    "    def parameter(self):\n",
    "        return [p for layer in self.layer for p in layer.parameter() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
